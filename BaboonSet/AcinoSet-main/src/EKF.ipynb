{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Kalman Filter & Smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from time import time\n",
    "from scipy.stats import linregress\n",
    "from lib import misc, utils, app\n",
    "from lib.calib import project_points_fisheye, triangulate_points_fisheye\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ROOT_DATA_DIR = os.path.join(\"/Users/matthewterblanche/Downloads/Baboon Data/AcinoSet-main\",\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Params\n",
    "Define the params in the cell below. Thereafter, run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(ROOT_DATA_DIR, \"2021_10_07\", \"Baboon1\", \"walk\")\n",
    "\n",
    "start_frame = 24320\n",
    "end_frame = 24720\n",
    "\n",
    "# DLC p_cutoff - any points with likelihood < dlc_thresh are not trusted in optimisation\n",
    "dlc_thresh = 0.5 # change this only if the optimisation result is unsatisfactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num States:  {'x_0': 0, 'y_0': 1, 'z_0': 2, 'phi_0': 3, 'theta_0': 4, 'psi_0': 5, 'phi_1': 6, 'theta_1': 7, 'psi_1': 8, 'theta_2': 9, 'theta_3': 10, 'psi_3': 11, 'theta_4': 12, 'psi_4': 13, 'theta_5': 14, 'psi_5': 15, 'theta_6': 16, 'psi_6': 17, 'theta_7': 18, 'psi_7': 19, 'theta_8': 20, 'psi_8': 21, 'theta_9': 22, 'psi_9': 23, 'theta_10': 24, 'theta_11': 25, 'theta_12': 26, 'theta_13': 27, 'theta_14': 28, 'theta_15': 29, 'theta_16': 30, 'theta_17': 31}\n",
      "Loaded extrinsics from /Users/matthewterblanche/Downloads/Baboon Data/AcinoSet-main/data/2021_10_07/extrinsic_calib/2_cam_scene_sba.json\n",
      "\n",
      "\n",
      "25603\n",
      "States:  [-0.08022598  5.2858925   0.          0.          0.         -0.18311446\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.1126786  -0.02086683  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n",
      "P init:  [[ 9.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  9.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  9. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ... 25.  0.  0.]\n",
      " [ 0.  0.  0. ...  0. 25.  0.]\n",
      " [ 0.  0.  0. ...  0.  0. 25.]]\n",
      "\n",
      "Initialization took 21.98 seconds\n",
      "\n",
      "Running frame 24320\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gs/xf7bp_1x2pn3n3snf7119p9r0000gn/T/ipykernel_62221/2978151462.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_cams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;31m# State measurement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_markers\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_markers\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvel_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcamera_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstart_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0;31m# Jacobian - shape: (2*n_markers, n_states)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_markers\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_markers\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvel_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvel_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcamera_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstart_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gs/xf7bp_1x2pn3n3snf7119p9r0000gn/T/ipykernel_62221/2978151462.py\u001b[0m in \u001b[0;36mh_function\u001b[0;34m(x, k, d, r, t, rot)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mcoords_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject_points_fisheye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Project the 3D positions to 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mcoords_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject_points_fisheye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_angles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Project the 3D positions to 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcoords_2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "# ========= INIT VARS ========\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "assert os.path.exists(DATA_DIR)\n",
    "OUT_DIR = os.path.join(DATA_DIR, 'ekf')\n",
    "DLC_DIR = os.path.join(DATA_DIR, 'dlc')\n",
    "assert os.path.exists(DLC_DIR)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "app.start_logging(os.path.join(OUT_DIR, 'ekf.log'))\n",
    "\n",
    "idx = misc.get_pose_params() # define the indices for the states\n",
    "markers = misc.get_markers() # define DLC labels\n",
    "\n",
    "n_markers = len(markers)\n",
    "n_pose_params = len(idx)\n",
    "n_states = 3*n_pose_params\n",
    "\n",
    "print(\"Num States: \",idx)\n",
    "\n",
    "vel_idx = n_states//3\n",
    "acc_idx = n_states*2//3\n",
    "\n",
    "derivs = {'d'+state: vel_idx+idx[state] for state in idx}\n",
    "derivs.update({'d'+state: vel_idx+derivs[state] for state in derivs})\n",
    "idx.update(derivs)\n",
    "\n",
    "# load video info\n",
    "res, fps, tot_frames, _ = app.get_vid_info(DATA_DIR) # path to original videos\n",
    "assert end_frame <= tot_frames, f'end_frame must be less than or equal to {tot_frames}'\n",
    "\n",
    "# Load extrinsic params\n",
    "k_arr, d_arr, r_arr, t_arr, cam_res, n_cams, scene_fpath = utils.find_scene_file(DATA_DIR)\n",
    "assert res == cam_res\n",
    "camera_params = [[K, D, R, T] for K, D, R, T in zip(k_arr, d_arr, r_arr, t_arr)]\n",
    "\n",
    "# other vars\n",
    "start_frame -= 1 # 0 based indexing\n",
    "assert start_frame >= 0\n",
    "n_frames = end_frame-start_frame\n",
    "sigma_bound = 3\n",
    "max_pixel_err = cam_res[0] # used in measurement covariance R\n",
    "sT = 1.0/fps # timestep\n",
    "\n",
    "# ========= FUNCTION DEFINITINOS ========\n",
    "\n",
    "def h_function(x: np.ndarray, k: np.ndarray, d: np.ndarray, r: np.ndarray, t: np.ndarray, rot: np.float32):\n",
    "    \"\"\"Returns a numpy array of the 2D marker pixel coordinates (shape Nx2) for a given state vector x and camera parameters k, d, r, t.\n",
    "    \"\"\"\n",
    "    coords_3d = misc.get_3d_marker_coords(x)\n",
    "    \n",
    "    coords_2d = project_points_fisheye(coords_3d, k, d, r, t) # Project the 3D positions to 2D\n",
    "\n",
    "    coords_2d = project_points_fisheye(coords_3d, k, d, rot_angles[n], t) # Project the 3D positions to 2D\n",
    "    \n",
    "    return coords_2d\n",
    "\n",
    "\n",
    "def predict_next_state(x: np.ndarray, dt: np.float32):\n",
    "    \"\"\"Returns a numpy array of the predicted states for a given state vector x and time delta dt.\n",
    "    \"\"\"\n",
    "    acc_prediction = x[acc_idx:]\n",
    "    \n",
    "    vel_prediction = x[vel_idx:acc_idx] + dt*acc_prediction\n",
    "\n",
    "    pos_prediction = x[:vel_idx] + dt*vel_prediction + (0.5*dt**2)*acc_prediction\n",
    "\n",
    "#    print(\"Next State: \",np.concatenate([pos_prediction, vel_prediction, acc_prediction]).astype(np.float32)) \n",
    "    return np.concatenate([pos_prediction, vel_prediction, acc_prediction]).astype(np.float32)\n",
    "\n",
    "\n",
    "def numerical_jacobian(func, x: np.ndarray, *args):\n",
    "    \"\"\"Returns a numerically approximated jacobian of func with respect to x.\n",
    "    Additional parameters will be passed to func using *args in the format: func(*x, *args)\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    eps = 1e-3\n",
    "    \n",
    "    fx = func(x, *args).flatten()\n",
    "    xpeturb=x.copy()\n",
    "    jac = np.empty((len(fx), n))\n",
    "    for i in range(n):\n",
    "        xpeturb[i] = xpeturb[i]+eps\n",
    "        jac[:,i] = (func(xpeturb, *args).flatten() - fx)/eps\n",
    "        xpeturb[i]=x[i]\n",
    "        \n",
    "    return jac\n",
    "\n",
    "\n",
    "# ========= LOAD DLC DATA ========\n",
    "\n",
    "# Load DLC 2D point files (.h5 outputs)\n",
    "dlc_2d_point_files = sorted(glob(os.path.join(DLC_DIR, '*.h5')))\n",
    "assert(len(dlc_2d_point_files) == n_cams), f\"# of dlc '.h5' files != # of cams in {n_cams}_cam_scene_sba.json\"\n",
    "\n",
    "# Load Measurement Data (pixels, likelihood)\n",
    "points_2d_df = utils.load_dlc_points_as_df(dlc_2d_point_files, verbose=False)\n",
    "\n",
    "points_3d_df = utils.get_pairwise_3d_points_from_df(\n",
    "    points_2d_df[points_2d_df['likelihood']>dlc_thresh], # ignore points with low likelihood\n",
    "    k_arr, d_arr.reshape((-1,4)), r_arr, t_arr,\n",
    "    triangulate_points_fisheye\n",
    ")\n",
    "\n",
    "def rot_y(y):\n",
    "    c = sp.cos(y)\n",
    "    s = sp.sin(y)\n",
    "    return sp.Matrix([\n",
    "        [c, 0, s],\n",
    "        [0, 1, 0],\n",
    "        [-s, 0, c]\n",
    "    ])\n",
    "#Load rotations csv\n",
    "\n",
    "rotation_csv_path = os.path.join(DATA_DIR, 'encoder6_rad.csv')\n",
    "\n",
    "rot_angles = []\n",
    "\n",
    "rotation = utils.load_rotation(rotation_csv_path)\n",
    "\n",
    "for i in rotation['Rotation (rad)'].values:\n",
    "    rot_angles.append(np.float32(rot_y(i)))\n",
    "\n",
    "print(len(rot_angles))\n",
    "\n",
    "# Restructure dataframe\n",
    "points_df = points_2d_df.set_index(['frame', 'camera','marker'])\n",
    "points_df = points_df.stack().unstack(level=1).unstack(level=1).unstack()\n",
    "\n",
    "# Pixels array\n",
    "pixels_df = points_df.loc[:, (range(n_cams), markers, ['x','y'])]\n",
    "pixels_df = pixels_df.reindex(columns=pd.MultiIndex.from_product([range(n_cams), markers, ['x','y']]))\n",
    "pixels_arr = pixels_df.to_numpy() #shape - (n_frames, n_cams * n_markers * 2)\n",
    "\n",
    "# Likelihood array\n",
    "likelihood_df = points_df.loc[:, (range(n_cams), markers, 'likelihood')]\n",
    "likelihood_df = likelihood_df.reindex(columns=pd.MultiIndex.from_product([range(n_cams), markers, ['likelihood']]))\n",
    "likelihood_arr = likelihood_df.to_numpy() #shape - (n_frames, n_cams * n_markers * 1)\n",
    "\n",
    "# ========= INITIALIZE EKF MATRICES ========\n",
    "\n",
    "# estimate initial points\n",
    "states = np.zeros(n_states)\n",
    "\n",
    "\n",
    "points_3d_df = points_3d_df[points_3d_df['frame'].between(start_frame, end_frame-1)]\n",
    "\n",
    "snout_pts = points_3d_df[points_3d_df[\"marker\"]==\"snout\"][[\"frame\", \"x\", \"y\", \"z\"]].values\n",
    "snout_x_slope, snout_x_intercept, *_ = linregress(snout_pts[:,0], snout_pts[:,1]) \n",
    "snout_y_slope, snout_y_intercept, *_ = linregress(snout_pts[:,0], snout_pts[:,2])\n",
    "\n",
    "snout_x_est = start_frame*snout_x_slope + snout_x_intercept # initial snout x\n",
    "snout_y_est = start_frame*snout_y_slope + snout_y_intercept # initial snout y\n",
    "snout_psi_est = np.arctan2(snout_y_slope, snout_x_slope)    # initial yaw angle relative to inertial\n",
    "\n",
    "# INITIAL STATES\n",
    "states[[idx['x_0'], idx['y_0'],idx['psi_0']]] = [snout_x_est, snout_y_est, snout_psi_est] # head x, y & psi (yaw) in inertial\n",
    "states[[idx['dx_0'], idx['dy_0']]] = [snout_x_slope/sT, snout_y_slope/sT]                # head x & y velocity in inertial\n",
    "\n",
    "print(\"States: \", states)\n",
    "\n",
    "\n",
    "\n",
    "# INITIAL STATE COVARIANCE P - how much do we trust the initial states\n",
    "# position\n",
    "p_lin_pos = np.ones(3)*3**2                       # Know initial position within 4m\n",
    "p_ang_pos = np.ones(n_pose_params-3)*(np.pi/4)**2 # Know initial angles within 60 degrees, heading may need to change\n",
    "# p_lure_pos = p_lin_pos\n",
    "# velocity\n",
    "p_lin_vel = np.ones(3)*5**2                       # Know this within 2.5m/s and it's a uniform random variable\n",
    "p_ang_vel = np.ones(n_pose_params-3)*3**2\n",
    "# p_lure_vel = p_lin_vel\n",
    "# acceleration\n",
    "p_lin_acc = np.ones(3)*3**2\n",
    "p_ang_acc = np.ones(n_pose_params-3)*3**2\n",
    "p_ang_acc[10:] = 5**2\n",
    "# p_lure_acc = p_lin_acc\n",
    "\n",
    "P = np.diag(np.concatenate([p_lin_pos, p_ang_pos, #p_lure_pos,\n",
    "                            p_lin_vel, p_ang_vel, #p_lure_vel,\n",
    "                            p_lin_acc, p_ang_acc, #p_lure_acc\n",
    "                           ]))\n",
    "print(\"P init: \",P)\n",
    "\n",
    "# PROCESS COVARIANCE Q - how \"noisy\" the constant acceleration model is\n",
    "qb_list = [\n",
    "    5.0, 5.0, 5.0,    # head x, y, z in inertial\n",
    "    10.0, 10.0, 10.0, # head phi, theta, psi in inertial\n",
    "    5.0, 25.0, 5.0,   # neck phi, theta, psi\n",
    "    50.0,             # front-torso theta\n",
    "    50.0, 25.0,       # spine 1 theta, psi\n",
    "    50.0, 25.0,       # spine 2 theta, psi\n",
    "    50.0, 25.0,       # spine 3 theta, psi\n",
    "    50.0, 25.0,       # back torso theta, psi\n",
    "    100.0, 30.0,      # tail base theta, psi\n",
    "    140.0, 40.0,      # tail 1 theta, psi\n",
    "    140.0, 40.0,      # tail 2 theta, psi\n",
    "    350.0, 200.0,     # left shoulder theta, left elbow theta\n",
    "    350.0, 200.0,     # right shoulder theta, right elbow theta\n",
    "    450.0, 400.0,     # left hip theta, left knee theta\n",
    "    450.0, 400.0,     # right hip theta, right knee theta\n",
    "]\n",
    "\n",
    "# qb_list = [\n",
    "#     12.5, 12.5, 12.5,    # head x, y, z in inertial\n",
    "#     50.0, 50.0, 50.0, # head phi, theta, psi in inertial\n",
    "#     12.5, 12.5, 12.5,   # neck phi, theta, psi\n",
    "#     1250.0,             # front-torso theta\n",
    "#     1250.0, 312.5,       # spine 1 theta, psi\n",
    "#     1250.0, 312.5,       # spine 2 theta, psi\n",
    "#     1250.0, 312.5,       # spine 3 theta, psi\n",
    "#     1250.0, 312.5,       # back torso theta, psi\n",
    "#     5000.0, 450.0,      # tail base theta, psi\n",
    "#     9800.0, 800.0,      # tail 1 theta, psi\n",
    "#     9800.0, 800.0,      # tail 2 theta, psi\n",
    "#     61250.0, 20000.0,     # left shoulder theta, left elbow theta\n",
    "#     61250.0, 20000.0,     # right shoulder theta, right elbow theta\n",
    "#     101250.0, 80000.0,     # left hip theta, left knee theta\n",
    "#     101250.0, 80000.0,     # right hip theta, right knee theta\n",
    "# ]\n",
    "# qb_list += qb_list[0:3] # lure x, y, z in inertial - same as head\n",
    "\n",
    "qb = (np.diag(qb_list)/2)**2\n",
    "Q = np.block([\n",
    "    [sT**4/4 * qb, sT**3/2 * qb, sT**2/2 * qb],\n",
    "    [sT**3/2 * qb, sT**2 * qb, sT * qb],\n",
    "    [sT**2/2 * qb, sT * qb, qb],\n",
    "])\n",
    "\n",
    "# MEASUREMENT COVARIANCE R\n",
    "dlc_cov = 6**2\n",
    "\n",
    "# State prediction function jacobian F - shape: (n_states, n_states)\n",
    "rng = np.arange(n_states - vel_idx)\n",
    "rng_acc = np.arange(n_states - acc_idx)\n",
    "F = np.eye(n_states)\n",
    "F[rng, rng+vel_idx] = sT\n",
    "F[rng_acc, rng_acc+acc_idx] = sT**2/2\n",
    "\n",
    "# Allocate space for storing EKF data\n",
    "states_est_hist = np.zeros((n_frames, n_states))\n",
    "states_pred_hist = states_est_hist.copy()\n",
    "P_est_hist = np.zeros((n_frames, n_states, n_states))\n",
    "P_pred_hist = P_est_hist.copy()\n",
    "\n",
    "t1 = time()\n",
    "print(\"\\nInitialization took {0:.2f} seconds\\n\".format(t1 - t0))\n",
    "\n",
    "# ========= RUN EKF & SMOOTHER ========\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "outliers_ignored = 0\n",
    "\n",
    "for i in range(n_frames):\n",
    "    print(f\"Running frame {i+start_frame+1}\\r\", end='')\n",
    "    \n",
    "    # ========== PREDICTION ==========\n",
    "\n",
    "    # Predict State\n",
    "    states = predict_next_state(states, sT).flatten()\n",
    "    states_pred_hist[i] = states\n",
    "\n",
    "    # Projection of the state covariance\n",
    "\n",
    "    P = F @ P @ F.T + Q\n",
    " \n",
    " \n",
    "    \n",
    "    P_pred_hist[i] = P\n",
    "    \n",
    "    # ============ UPDATE ============\n",
    "    \n",
    "    z_k = pixels_arr[i+start_frame]\n",
    "    likelihood = likelihood_arr[i+start_frame]\n",
    "    \n",
    "    # Measurement\n",
    "    H = np.zeros((n_cams*n_markers*2, n_states))\n",
    "    h = np.zeros((n_cams*n_markers*2)) # same as H[:, 0].copy()\n",
    "    for j in range(n_cams):\n",
    "        # State measurement\n",
    "        h[j*n_markers*2:(j+1)*n_markers*2] = h_function(states[:vel_idx], *camera_params[j], i+start_frame).flatten()\n",
    "        # Jacobian - shape: (2*n_markers, n_states)\n",
    "        H[j*n_markers*2:(j+1)*n_markers*2, 0:vel_idx] = numerical_jacobian(h_function, states[:vel_idx], *camera_params[j],i+start_frame)\n",
    "    \n",
    "    # Measurement Covariance R\n",
    "    bad_point_mask = np.repeat(likelihood<dlc_thresh, 2)\n",
    "    dlc_cov_arr = dlc_cov*np.ones((n_cams*n_markers*2))\n",
    "    dlc_cov_arr[bad_point_mask] = max_pixel_err # change this to be independent of cam res?\n",
    "    R = np.diag(dlc_cov_arr**2)\n",
    "\n",
    "    # Residual\n",
    "    residual = z_k - h\n",
    "\n",
    "    # Residual Covariance S\n",
    "    S = (H @ P @ H.T) + R\n",
    "    temp = sigma_bound*np.sqrt(np.diag(S)) # if measurement residual is worse than 3 sigma, set residual to 0 and rely on predicted state only\n",
    "    for j in range(0, len(residual), 2):\n",
    "        if np.abs(residual[j])>temp[j] or np.abs(residual[j+1])>temp[j+1]:\n",
    "            residual[j:j+2] = 0\n",
    "            outliers_ignored += 1\n",
    "\n",
    "    # Kalman Gain\n",
    "    K = P @ H.T @ np.linalg.inv(S)\n",
    "\n",
    "    # Correction\n",
    "    states = states + K @ residual\n",
    "    states_est_hist[i] = states\n",
    "\n",
    "    # Update State Covariance\n",
    "    P = (np.eye(K.shape[0]) - K @ H) @ P\n",
    "    P_est_hist[i] = P\n",
    "\n",
    "print(\"EKF complete!\")\n",
    "print(\"Outliers ignored:\", outliers_ignored)\n",
    "\n",
    "# Run Kalman Smoother\n",
    "smooth_states_est_hist = states_est_hist.copy()\n",
    "smooth_P_est_hist = P_est_hist.copy()\n",
    "for i in range(n_frames-2, 0, -1):\n",
    "    A = P_est_hist[i] @ F.T @ np.linalg.inv(P_pred_hist[i+1])\n",
    "    smooth_states_est_hist[i] = states_est_hist[i] + A @ (smooth_states_est_hist[i+1] - states_pred_hist[i+1])\n",
    "    smooth_P_est_hist[i] = P_est_hist[i] + A @ (smooth_P_est_hist[i+1] - P_pred_hist[i+1]) @ A.T\n",
    "    \n",
    "print(\"\\nKalman Smoother complete!\\n\")\n",
    "t1 = time()\n",
    "print(\"Optimization took {0:.2f} seconds\\n\".format(t1 - t0))\n",
    "\n",
    "app.stop_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save EKF results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = dict(x=states_est_hist[:, :vel_idx],\n",
    "              dx=states_est_hist[:, vel_idx:acc_idx],\n",
    "              ddx=states_est_hist[:, acc_idx:],\n",
    "              smoothed_x=smooth_states_est_hist[:, :vel_idx],\n",
    "              smoothed_dx=smooth_states_est_hist[:, vel_idx:acc_idx],\n",
    "              smoothed_ddx=smooth_states_est_hist[:, acc_idx:]\n",
    "             )\n",
    "app.save_ekf(states, OUT_DIR, scene_fpath, start_frame, dlc_thresh)\n",
    "\n",
    "fig_fpath= os.path.join(OUT_DIR, 'ekf.svg')\n",
    "app.plot_baboon_states(states['x'], states['smoothed_x'], fig_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the baboon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = os.path.join(OUT_DIR, 'ekf.pickle')\n",
    "app.plot_baboon_reconstruction(data_fpath, reprojections=True, centered=False, dark_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
